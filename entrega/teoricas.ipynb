{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repositórios\n",
    "\n",
    "Parte 1: https://github.com/pedromvba/data-driven-apps-tp2-part1.git\n",
    "Parte 2: https://github.com/pedromvba/data-driven-apps-tp2-part2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitações quanto à precisão da tradução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As limitações do modelo quanto a precisão da tradução irão depender do tamanho do modelo, ou seja, da quantidade de parâmetros utilizados no treinamento, bem como a quantidade de dados. Quanto maior o modelo, mais capaz ele será de (i) compreender corretamente o texto encaminhado e (ii) retornar uma tradução adequada.\n",
    "\n",
    "Adicionalmente, um outro ponto que pode impactar a precisão do modelo é a diversidade dos dados de treinamento, inclusive com a presença ou não de gírias e expressões mais coloquiais. Por exemplo, caso o modelo tenha sido treinado utilizando uma linguagem mais formal e/ou antiga, provavelmente não terá uma boa precisão ao precisar traduzir gírias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafios de tempo de resposta e desempenho em grande escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os desafios de tempo de resposta e desempenham em grande escala passam muito pela infraestrutura disponível para a execução do modelo. Para melhorar esses pontos é interessante a utilização de infraestururas específicas para esse tipo de tarefa, como por exemplo a utilização de GPUs ao invés de CPUs. GPUs conseguem lidar melhor com operações paralelas, o que as torna ideais para o treinamento e a inferência de modelos de deep learning. Assim, esse tipo de infraestutura pode reduzir significativamente o tempo de resposta e aumentar a eficiência do modelo, permitindo que ele trabalhe com mais dados, ou seja, em grande escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrições de custo e escalabilidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos mais capazes são muito custosos para serem treinados, necessitando de infraestruturas mais custosas. Assim, normalmente não são disponibilizados de forma gratuita, havendo a necessidade de uma assinatura mensal ou algum tipo de retorno para a empresa. Mesmo os modelos gratuitos que possuem maior capacidade, necessitam de uma infraestutura local mais robusta, o que também gera maiores custos e inviabiliza a escalabilidade do aplicativo a um determinado nível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitações na tradução de gírias, expressões idiomáticas ou linguagem de contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme registrado anteriormente, podem ocorrer limitações na tradução de gírias, expressões idiomáticas ou linguagem de contexto devido tanto ao tamanho do modelo quanto aos dados de treinamento. Por exemplo, caso o modelo tenha sido treinado utilizando uma linguagem mais formal e/ou antiga, provavelmente não terá uma boa precisão ao precisar traduzir gírias. Dessa forma, para termos um modelo com um bom desempenho em traduzir gírias e outros termos mais coloquiais, deve-se garantir que esses dados estarão no treinamento, bem como uma quantidade de parâmetros adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A coerência do texto gerado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coerência do texto gerado dependerá do tamanho do modelo, ou seja, da quantidade de parâmetros utilizados no treinamento, bem como a quantidade de dados. Quanto maior o modelo, mais capaz ele será de (i) compreender corretamente o texto encaminhado e (ii) retornar uma tradução adequada. Adicionalmente, um outro ponto que pode impactar a precisão do modelo é a diversidade dos dados de treinamento. \n",
    "\n",
    "O modelo utilizado no caso foi o GPT2, treinado com 1,5 bilhão de parâmetros. Assim, o modelo possui uma tendência maior de apresentar uma falta de coerência no texto gerado, conhecida popularmente como alucinação, do que em modelos com mais parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Possíveis falhas ou incoerências geradas por LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Possíveis falhar ou incoerências geradas por LLMs podem decorrer de diversos fatores, 2 deles já abordados como a limitações/sensibilidade ao contexto dos dados de treinamento e alucinações.\n",
    "\n",
    "Outro motivo que pode ocorrer também decorre dos dados de treinamento que podem conter bias e/ou preconceitos embutidos, acarretando os respectivos reflexos nas respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desempenho e questões de latência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho e a latência, quando executados localmente, dependerão da infraestrutura que está sendo utilizada para a execução do modelo. Quanto mais dedicada e robusta, como por exemplo, com o uso de GPUs para grandes escalas melhor será o desempenho e menor a latência da aplicação. Importante registrar também que o desempenho da aplicação, principalmente em termos de precisão, dependerá do tamanho e da arquitetura do modelo sendo utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitações na geração de conteúdo apropriado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme já registrado, o conteúdo gerado pelo modelo por muitas vezes não ser adequado devido a bias e/ou preconceitos nos dados de treinamento que impactarão as respostas. De forma a evitar esse tipo de comportamento, dentre outras soluções, pode ser utilizada curadorias dos dados de treinamento, bem como supervisão das respostas do modelo antes do retorno ao usuário, supervisão que pode ser realizada inclusive por outro modelo que tenha sido treinado com foco em textos e normas éticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
